{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data Preparation\n",
    "## 1.1 Planning data structure \n",
    "- I need to build a 3d dataset for transformer model analysis, first dimension is time, second is window size which is 7, third dimension is all the other features. \n",
    "- using numpy & pandas for data preparation\n",
    "- using pytorch for building transformer models\n",
    "\n",
    "## 1.2 feature adjacent matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First process the raw data of adjacency to a binary matrix for future modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           County_1  County_2  County_3  County_4  County_5  County_6  \\\n",
      "County_1          1         0         0         0         1         0   \n",
      "County_2          0         1         1         0         1         0   \n",
      "County_3          0         1         1         0         1         0   \n",
      "County_4          0         0         0         1         0         1   \n",
      "County_5          1         1         1         0         1         0   \n",
      "County_6          0         0         0         1         0         1   \n",
      "County_7          1         0         1         0         1         0   \n",
      "County_8          0         0         0         0         0         0   \n",
      "County_9          0         1         1         0         1         0   \n",
      "County_10         0         1         0         0         0         0   \n",
      "County_11         0         0         0         1         0         1   \n",
      "County_12         0         0         0         0         0         0   \n",
      "County_13         0         0         0         0         0         0   \n",
      "County_14         0         1         0         0         0         0   \n",
      "County_15         0         0         0         0         0         0   \n",
      "County_16         0         0         0         0         0         0   \n",
      "County_17         0         0         0         1         0         1   \n",
      "County_18         0         0         0         1         0         0   \n",
      "County_19         0         0         0         0         0         0   \n",
      "County_20         0         1         0         0         0         0   \n",
      "County_21         1         0         0         0         0         0   \n",
      "County_22         0         1         0         0         1         0   \n",
      "County_23         0         0         0         1         0         1   \n",
      "County_24         1         0         0         0         1         0   \n",
      "County_25         0         0         0         0         0         0   \n",
      "County_26         0         1         1         0         1         0   \n",
      "County_27         0         0         0         0         0         0   \n",
      "County_28         0         0         0         0         0         1   \n",
      "County_29         0         0         0         1         0         0   \n",
      "County_30         0         0         0         0         0         0   \n",
      "County_31         0         1         1         1         0         1   \n",
      "County_32         0         0         0         1         0         0   \n",
      "County_33         0         0         0         0         0         0   \n",
      "County_34         1         1         1         0         1         1   \n",
      "County_35         1         0         0         0         0         0   \n",
      "County_36         0         0         0         0         0         0   \n",
      "County_37         0         0         0         0         0         0   \n",
      "County_38         1         0         0         0         0         0   \n",
      "County_39         1         0         1         0         1         0   \n",
      "County_40         0         0         0         0         0         0   \n",
      "County_41         1         0         0         0         0         0   \n",
      "County_42         0         0         0         0         0         0   \n",
      "County_43         1         0         0         0         1         0   \n",
      "County_44         1         0         0         0         0         0   \n",
      "County_45         0         0         0         1         0         0   \n",
      "County_46         0         0         0         1         0         0   \n",
      "County_47         0         0         0         0         0         0   \n",
      "County_48         1         0         1         0         0         1   \n",
      "County_49         0         0         0         0         0         1   \n",
      "County_50         1         1         1         0         1         0   \n",
      "County_51         0         0         0         1         0         1   \n",
      "County_52         0         0         0         1         0         1   \n",
      "County_53         0         0         0         1         0         0   \n",
      "County_54         0         0         0         0         0         0   \n",
      "County_55         0         1         1         0         1         0   \n",
      "County_56         0         0         0         0         0         0   \n",
      "County_57         0         0         1         1         0         1   \n",
      "County_58         0         0         0         1         0         1   \n",
      "\n",
      "           County_7  County_8  County_9  County_10  ...  County_49  County_50  \\\n",
      "County_1          1         0         0          0  ...          0          1   \n",
      "County_2          0         0         1          1  ...          0          1   \n",
      "County_3          1         0         1          0  ...          0          1   \n",
      "County_4          0         0         0          0  ...          0          0   \n",
      "County_5          1         0         1          0  ...          0          1   \n",
      "County_6          0         0         0          0  ...          1          0   \n",
      "County_7          1         0         1          0  ...          1          1   \n",
      "County_8          0         1         0          0  ...          0          0   \n",
      "County_9          1         0         1          0  ...          0          0   \n",
      "County_10         0         0         0          1  ...          0          1   \n",
      "County_11         0         0         0          0  ...          1          0   \n",
      "County_12         0         1         0          0  ...          1          0   \n",
      "County_13         0         0         0          0  ...          0          0   \n",
      "County_14         0         0         0          1  ...          0          0   \n",
      "County_15         0         0         0          1  ...          0          0   \n",
      "County_16         0         0         0          1  ...          0          0   \n",
      "County_17         0         0         0          0  ...          1          0   \n",
      "County_18         0         0         0          0  ...          0          0   \n",
      "County_19         0         0         0          0  ...          0          0   \n",
      "County_20         0         0         0          1  ...          0          1   \n",
      "County_21         1         0         0          0  ...          1          0   \n",
      "County_22         0         0         0          1  ...          0          1   \n",
      "County_23         0         1         0          0  ...          1          0   \n",
      "County_24         0         0         0          1  ...          0          1   \n",
      "County_25         0         1         0          0  ...          0          0   \n",
      "County_26         0         0         1          1  ...          0          1   \n",
      "County_27         0         0         0          1  ...          0          0   \n",
      "County_28         1         0         0          0  ...          1          0   \n",
      "County_29         0         0         1          0  ...          0          0   \n",
      "County_30         0         0         0          0  ...          0          0   \n",
      "County_31         1         0         1          0  ...          0          0   \n",
      "County_32         0         0         0          0  ...          0          0   \n",
      "County_33         0         0         0          0  ...          0          0   \n",
      "County_34         1         0         1          0  ...          0          1   \n",
      "County_35         0         0         0          1  ...          0          1   \n",
      "County_36         0         0         0          1  ...          0          0   \n",
      "County_37         0         0         0          0  ...          0          0   \n",
      "County_38         1         0         0          0  ...          1          0   \n",
      "County_39         1         0         1          0  ...          0          1   \n",
      "County_40         0         0         0          1  ...          0          0   \n",
      "County_41         1         0         0          0  ...          0          1   \n",
      "County_42         0         0         0          0  ...          0          0   \n",
      "County_43         1         0         0          1  ...          0          1   \n",
      "County_44         0         0         0          1  ...          0          1   \n",
      "County_45         0         1         0          0  ...          0          0   \n",
      "County_46         0         0         0          0  ...          0          0   \n",
      "County_47         0         1         0          0  ...          0          0   \n",
      "County_48         1         0         1          0  ...          1          0   \n",
      "County_49         1         0         0          0  ...          1          0   \n",
      "County_50         1         0         0          1  ...          0          1   \n",
      "County_51         0         0         1          0  ...          0          0   \n",
      "County_52         0         0         0          0  ...          1          0   \n",
      "County_53         0         1         0          0  ...          1          0   \n",
      "County_54         0         0         0          1  ...          0          0   \n",
      "County_55         0         0         1          1  ...          0          1   \n",
      "County_56         0         0         0          0  ...          0          0   \n",
      "County_57         1         0         1          0  ...          1          0   \n",
      "County_58         0         0         1          0  ...          0          0   \n",
      "\n",
      "           County_51  County_52  County_53  County_54  County_55  County_56  \\\n",
      "County_1           0          0          0          0          0          0   \n",
      "County_2           0          0          0          0          1          0   \n",
      "County_3           0          0          0          0          1          0   \n",
      "County_4           1          1          1          0          0          0   \n",
      "County_5           0          0          0          0          1          0   \n",
      "County_6           1          1          0          0          0          0   \n",
      "County_7           0          0          0          0          0          0   \n",
      "County_8           0          0          1          0          0          0   \n",
      "County_9           1          0          0          0          1          0   \n",
      "County_10          0          0          0          1          1          0   \n",
      "County_11          1          1          1          0          0          0   \n",
      "County_12          0          1          1          0          0          0   \n",
      "County_13          0          0          0          0          0          0   \n",
      "County_14          0          0          0          1          1          1   \n",
      "County_15          0          0          0          1          0          1   \n",
      "County_16          0          0          0          1          0          1   \n",
      "County_17          1          1          1          0          0          0   \n",
      "County_18          0          1          1          0          0          0   \n",
      "County_19          0          0          0          1          0          1   \n",
      "County_20          0          0          0          1          1          0   \n",
      "County_21          0          0          0          0          0          0   \n",
      "County_22          0          0          0          0          1          0   \n",
      "County_23          0          1          1          0          0          0   \n",
      "County_24          0          0          0          1          1          0   \n",
      "County_25          0          0          1          0          0          0   \n",
      "County_26          0          0          0          1          1          0   \n",
      "County_27          0          0          0          1          0          0   \n",
      "County_28          1          0          0          0          0          0   \n",
      "County_29          1          0          0          0          0          0   \n",
      "County_30          0          0          0          0          0          1   \n",
      "County_31          1          0          0          0          0          0   \n",
      "County_32          1          1          1          0          0          0   \n",
      "County_33          0          0          0          0          0          0   \n",
      "County_34          1          0          0          0          0          0   \n",
      "County_35          0          0          0          1          0          0   \n",
      "County_36          0          0          0          1          0          1   \n",
      "County_37          0          0          0          0          0          0   \n",
      "County_38          0          0          0          0          0          0   \n",
      "County_39          0          0          0          0          1          0   \n",
      "County_40          0          0          0          1          0          1   \n",
      "County_41          0          0          0          0          0          0   \n",
      "County_42          0          0          0          0          0          1   \n",
      "County_43          0          0          0          0          1          0   \n",
      "County_44          0          0          0          0          0          0   \n",
      "County_45          0          1          1          0          0          0   \n",
      "County_46          1          1          0          0          0          0   \n",
      "County_47          0          1          1          0          0          0   \n",
      "County_48          1          0          0          0          0          0   \n",
      "County_49          0          1          1          0          0          0   \n",
      "County_50          0          0          0          0          1          0   \n",
      "County_51          1          1          0          0          0          0   \n",
      "County_52          1          1          1          0          0          0   \n",
      "County_53          0          1          1          0          0          0   \n",
      "County_54          0          0          0          1          0          1   \n",
      "County_55          0          0          0          0          1          0   \n",
      "County_56          0          0          0          1          0          1   \n",
      "County_57          1          0          0          0          0          0   \n",
      "County_58          1          1          0          0          0          0   \n",
      "\n",
      "           County_57  County_58  \n",
      "County_1           0          0  \n",
      "County_2           0          0  \n",
      "County_3           1          0  \n",
      "County_4           1          1  \n",
      "County_5           0          0  \n",
      "County_6           1          1  \n",
      "County_7           1          0  \n",
      "County_8           0          0  \n",
      "County_9           1          1  \n",
      "County_10          0          0  \n",
      "County_11          1          1  \n",
      "County_12          0          0  \n",
      "County_13          0          0  \n",
      "County_14          0          0  \n",
      "County_15          0          0  \n",
      "County_16          0          0  \n",
      "County_17          1          0  \n",
      "County_18          0          0  \n",
      "County_19          0          0  \n",
      "County_20          0          0  \n",
      "County_21          0          0  \n",
      "County_22          0          0  \n",
      "County_23          0          0  \n",
      "County_24          0          0  \n",
      "County_25          0          0  \n",
      "County_26          0          0  \n",
      "County_27          0          0  \n",
      "County_28          1          0  \n",
      "County_29          0          1  \n",
      "County_30          0          0  \n",
      "County_31          1          1  \n",
      "County_32          0          1  \n",
      "County_33          0          0  \n",
      "County_34          1          1  \n",
      "County_35          0          0  \n",
      "County_36          0          0  \n",
      "County_37          0          0  \n",
      "County_38          0          0  \n",
      "County_39          1          0  \n",
      "County_40          0          0  \n",
      "County_41          0          0  \n",
      "County_42          0          0  \n",
      "County_43          0          0  \n",
      "County_44          0          0  \n",
      "County_45          0          0  \n",
      "County_46          0          1  \n",
      "County_47          0          0  \n",
      "County_48          1          0  \n",
      "County_49          1          0  \n",
      "County_50          0          0  \n",
      "County_51          1          1  \n",
      "County_52          0          1  \n",
      "County_53          0          0  \n",
      "County_54          0          0  \n",
      "County_55          0          0  \n",
      "County_56          0          0  \n",
      "County_57          1          1  \n",
      "County_58          1          1  \n",
      "\n",
      "[58 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "add_adj = True\n",
    "add_dvmt = False\n",
    "add_popu = False\n",
    "add_vict = True\n",
    "\n",
    "# Read the Excel file for adjacency data\n",
    "file_path = r'./data/adjacent.xlsx'\n",
    "df_adj = pd.read_excel(file_path)\n",
    "\n",
    "# Extract all columns related to adjacency information\n",
    "adjacency_columns = df_adj.columns[1:]\n",
    "\n",
    "# Initialize the binary adjacency matrix\n",
    "num_counties = df_adj['County ID'].max()\n",
    "adjacency_matrix = np.zeros((num_counties, num_counties), dtype=int)\n",
    "\n",
    "for index, row in df_adj.iterrows():\n",
    "    county_id = int(row['County ID'])\n",
    "    \n",
    "    for col in adjacency_columns:\n",
    "        adjacents = row[col]\n",
    "        \n",
    "        adjacency_matrix[county_id - 1, county_id - 1] = 1\n",
    "        # Check if the cell is not NaN and is a valid adjacency entry\n",
    "        if pd.notna(adjacents):\n",
    "            adjacents = int(adjacents)  # Convert to integer\n",
    "            adjacency_matrix[county_id - 1, adjacents - 1] = 1\n",
    "\n",
    "# Convert the matrix to a DataFrame for better visualization\n",
    "adjacency_df = pd.DataFrame(adjacency_matrix, columns=[f'County_{i+1}' for i in range(num_counties)],\n",
    "                            index=[f'County_{i+1}' for i in range(num_counties)])\n",
    "\n",
    "print(adjacency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alameda': 1, 'Alpine': 2, 'Amador': 3, 'Butte': 4, 'Calaveras': 5, 'Colusa': 6, 'Contra Costa': 7, 'Del Norte': 8, 'El Dorado': 9, 'Fresno': 10, 'Glenn': 11, 'Humboldt': 12, 'Imperial': 13, 'Inyo': 14, 'Kern': 15, 'Kings': 16, 'Lake': 17, 'Lassen': 18, 'Los Angeles SPL': 19, 'Madera': 20, 'Marin': 21, 'Mariposa': 22, 'Mendocino': 23, 'Merced': 24, 'Modoc': 25, 'Mono': 26, 'Monterey': 27, 'Napa': 28, 'Nevada': 29, 'Orange': 30, 'Placer': 31, 'Plumas': 32, 'Riverside': 33, 'Sacramento': 34, 'San Benito': 35, 'San Bernardino': 36, 'San Diego': 37, 'San Francisco': 38, 'San Joaquin': 39, 'San Luis Obispo': 40, 'San Mateo': 41, 'Santa Barbara': 42, 'Santa Clara': 43, 'Santa Cruz': 44, 'Shasta': 45, 'Sierra': 46, 'Siskiyou': 47, 'Solano': 48, 'Sonoma': 49, 'Stanislaus': 50, 'Sutter': 51, 'Tehama': 52, 'Trinity': 53, 'Tulare': 54, 'Tuolumne': 55, 'Ventura': 56, 'Yolo': 57, 'Yuba': 58}\n",
      "['Alameda', 'Alpine', 'Amador', 'Butte', 'Calaveras', 'Colusa', 'Contra Costa', 'Del Norte', 'El Dorado', 'Fresno', 'Glenn', 'Humboldt', 'Imperial', 'Inyo', 'Kern', 'Kings', 'Lake', 'Lassen', 'Los Angeles SPL', 'Madera', 'Marin', 'Mariposa', 'Mendocino', 'Merced', 'Modoc', 'Mono', 'Monterey', 'Napa', 'Nevada', 'Orange', 'Placer', 'Plumas', 'Riverside', 'Sacramento', 'San Benito', 'San Bernardino', 'San Diego', 'San Francisco', 'San Joaquin', 'San Luis Obispo', 'San Mateo', 'Santa Barbara', 'Santa Clara', 'Santa Cruz', 'Shasta', 'Sierra', 'Siskiyou', 'Solano', 'Sonoma', 'Stanislaus', 'Sutter', 'Tehama', 'Trinity', 'Tulare', 'Tuolumne', 'Ventura', 'Yolo', 'Yuba']\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file\n",
    "file_path = r'./data/Victims_California_Counties.xlsx'\n",
    "sheets = pd.ExcelFile(file_path)\n",
    "sheet_names = sorted(sheets.sheet_names)\n",
    "county_map = {}\n",
    "for i, name in enumerate(sheet_names, 1):\n",
    "    county_map[name] = i\n",
    "print(county_map)\n",
    "print(sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Cleaning and Combing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to create a comprehensive dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inspect the quantity of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254214, 6)\n"
     ]
    }
   ],
   "source": [
    "county_id = 0\n",
    "all_adj_data = []\n",
    "\n",
    "for county_id in range(len(sheets.sheet_names)):\n",
    "    single_county_df = pd.read_excel(file_path, sheet_name=sheet_names[county_id])\n",
    "    if '2+5' in single_county_df.columns:\n",
    "        single_county_df.rename(columns={'2+5': '5+2'}, inplace=True)\n",
    "    if 'Date' in single_county_df.columns:\n",
    "        single_county_df.rename(columns={'Date': 'Year'}, inplace=True)\n",
    "\n",
    "    single_county_df = single_county_df[['Year', 1, '5+2', '6+3', '7+4']]\n",
    "    cols_to_rename = {\"Year\": 'Date', 1: 'Killed', '5+2': 'Suspected Serious Injury', '6+3': 'Suspected Minor Injury', '7+4': 'Possible Injury'}\n",
    "    for col in cols_to_rename:\n",
    "        if col in single_county_df.columns:\n",
    "            single_county_df.rename(columns={col: cols_to_rename[col]}, inplace=True)\n",
    "    \n",
    "    single_county_adj_df = single_county_df.copy()\n",
    "    single_county_adj_df['County_id'] = county_id + 1\n",
    "    cols = [c for c in single_county_adj_df.columns if c != 'County_id']\n",
    "    single_county_adj_df = single_county_adj_df[['County_id'] + cols].iloc[:4383]\n",
    "\n",
    "    all_adj_data.append(single_county_adj_df.copy())\n",
    "\n",
    "all_adj_data = pd.concat(all_adj_data, axis=0, ignore_index=True)\n",
    "print(all_adj_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adj_data.to_csv(r'./all_data_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Killed</th>\n",
       "      <th>Suspected Serious Injury</th>\n",
       "      <th>Suspected Minor Injury</th>\n",
       "      <th>Possible Injury</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-02 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-03 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-04 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-05 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   County_id                 Date  Killed  Suspected Serious Injury  \\\n",
       "0          1  2012-01-01 00:00:00       0                         1   \n",
       "1          1  2012-01-02 00:00:00       0                         3   \n",
       "2          1  2012-01-03 00:00:00       0                         0   \n",
       "3          1  2012-01-04 00:00:00       0                         0   \n",
       "4          1  2012-01-05 00:00:00       1                         1   \n",
       "\n",
       "   Suspected Minor Injury  Possible Injury  \n",
       "0                       1               19  \n",
       "1                       4                9  \n",
       "2                       2               18  \n",
       "3                       5               16  \n",
       "4                       8               28  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "all_adj_data = pd.read_csv(r'./all_data_adj.csv')\n",
    "all_adj_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Integer Validation:\n",
    "Defines is_integer function to check if values can be converted to integers.\n",
    "- Filtering and Conversion:\n",
    "Applies is_integer to filter out non-integer values in columns: 'Killed', 'Suspected Serious Injury', 'Suspected Minor Injury', and 'Possible Injury'.\n",
    "- Converts these columns to integer type.\n",
    "- Date Conversion:\n",
    "Converts 'Date' column to datetime format.\n",
    "- Data Cleaning:\n",
    "Drops rows with any missing values, ensuring a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_integer(val):\n",
    "    try:\n",
    "        return float(val).is_integer()\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "cols = ['Killed', 'Suspected Serious Injury',\n",
    "       'Suspected Minor Injury', 'Possible Injury']\n",
    "\n",
    "for col in cols:\n",
    "    all_adj_data = all_adj_data[all_adj_data[col].apply(is_integer)]\n",
    "    all_adj_data.loc[col] = all_adj_data[col].astype(int)\n",
    "\n",
    "all_adj_data.loc[:, 'Date'] = pd.to_datetime(all_adj_data['Date'], format='mixed')\n",
    "all_adj_data.dropna(axis=0, inplace=True)\n",
    "all_adj_data.loc[:, 'Date'] = pd.to_datetime(all_adj_data['Date'], format=\"mixed\").dt.date\n",
    "all_adj_data['Date'] = all_adj_data['Date'].astype(str)\n",
    "all_adj_data['County_id'] = all_adj_data['County_id'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Crash Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254214, 64)\n"
     ]
    }
   ],
   "source": [
    "file_path = r'./data/California County Crash Victims_ Corrected.xlsx'\n",
    "sheets = pd.ExcelFile(file_path)\n",
    "sheet_names = sorted(sheets.sheet_names)\n",
    "county_id = 0\n",
    "crash_data = []\n",
    "\n",
    "for county_id in range(len(sheets.sheet_names)):\n",
    "    single_county_df = pd.read_excel(file_path, sheet_name=sheet_names[county_id])\n",
    "\n",
    "    if '1' in single_county_df.columns and 'Fatal (1)' not in single_county_df.columns:\n",
    "        single_county_df.rename(columns={'1': 'Fatal (1)'}, inplace=True)\n",
    "    if 1 in single_county_df.columns and 'Fatal (1)' not in single_county_df.columns:\n",
    "        single_county_df.rename(columns={1: 'Fatal (1)'}, inplace=True)\n",
    "    if '1.1' in single_county_df.columns:\n",
    "        single_county_df.rename(columns={'1.1': 'Injury Severe -2'}, inplace=True)\n",
    "    if '8' in single_county_df.columns:\n",
    "        single_county_df.rename(columns={'8': 'Injury Other Visible - 3'}, inplace=True)\n",
    "    if 8 in single_county_df.columns:\n",
    "        single_county_df.rename(columns={8: 'Injury Other Visible - 3'}, inplace=True)\n",
    "    if '8.1' in single_county_df.columns:\n",
    "        single_county_df.rename(columns={'8.1': 'Injury Complaint of Pain - 4'}, inplace=True)\n",
    "\n",
    "    single_county_df = single_county_df[['Collision Date', 'Fatal (1)', 'Injury Severe -2', 'Injury Other Visible - 3', 'Injury Complaint of Pain - 4']]\n",
    "    cols_to_rename = {\"Collision Date\": 'Date', 'Fatal (1)': 'Fatal', 'Injury Severe -2': 'Injury Severe', \n",
    "                      'Injury Other Visible - 3': 'Injury Other Visible', 'Injury Complaint of Pain - 4': 'Injury Complaint of Pain'}\n",
    "    for col in cols_to_rename:\n",
    "        if col in single_county_df.columns:\n",
    "            single_county_df.rename(columns={col: cols_to_rename[col]}, inplace=True)\n",
    "\n",
    "    # Concatenate the original DataFrame and the new list DataFrame horizontally\n",
    "    single_county_df['County_id'] = county_id + 1\n",
    "    cols = [c for c in single_county_df.columns if c != 'County_id']\n",
    "    single_county_df = single_county_df[['County_id'] + cols].iloc[:4383]\n",
    "\n",
    "    adj = list(adjacency_df.iloc[county_id])\n",
    "    adj_df = pd.DataFrame([adj], columns=[f'Adjacency_{i+1}' for i in range(len(adj))])\n",
    "\n",
    "    # Duplicate the row to match the length of the original DataFrame\n",
    "    adj_df = pd.concat([adj_df] * len(single_county_df), ignore_index=True)\n",
    "\n",
    "    # Concatenate the original DataFrame and the new list DataFrame horizontally\n",
    "    if add_adj:\n",
    "        single_county_adj_df = pd.concat([single_county_df.copy(), adj_df.copy()], axis=1)\n",
    "    else:\n",
    "        single_county_adj_df = single_county_df.copy()\n",
    "    \n",
    "    crash_data.append(single_county_adj_df.copy())\n",
    "\n",
    "crash_data = pd.concat(crash_data, axis=0, ignore_index=True)\n",
    "\n",
    "crash_data.loc[:, 'Date'] = pd.to_datetime(crash_data['Date'], format=\"mixed\").dt.date\n",
    "crash_data['Date'] = crash_data['Date'].astype(str)\n",
    "crash_data['County_id'] = crash_data['County_id'].astype(int)\n",
    "print(crash_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254214, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'./data/California Counties Population.xlsx'\n",
    "sheets = pd.ExcelFile(file_path)\n",
    "sheet_names = sorted(sheets.sheet_names)\n",
    "\n",
    "county_map = {'Alameda': 1, 'Alpine': 2, 'Amador': 3, 'Butte': 4, 'Calaveras': 5, 'Colusa': 6, 'Contra Costa': 7, 'Del Norte': 8, 'El Dorado': 9, 'Fresno': 10, 'Glenn': 11, 'Humboldt': 12, 'Imperial': 13, 'Inyo': 14, 'Kern': 15, 'Kings': 16, 'Lake': 17, 'Lassen': 18, 'Los Angeles': 19, 'Madera': 20, 'Marin': 21, 'Mariposa': 22, 'Mendocino': 23, 'Merced': 24, 'Modoc': 25, 'Mono': 26, 'Monterey': 27, 'Napa': 28, 'Nevada': 29, 'Orange': 30, 'Placer': 31, 'Plumas': 32, 'Riverside': 33, 'Sacramento': 34, 'San Benito': 35, 'San Bernardino': 36, 'San Diego': 37, 'San Francisco': 38, 'San Joaquin': 39, 'San Luis Obispo': 40, 'San Mateo': 41, 'Santa Barbara': 42, 'Santa Clara': 43, 'Santa Cruz': 44, 'Shasta': 45, 'Sierra': 46, 'Siskiyou': 47, 'Solano': 48, 'Sonoma': 49, 'Stanislaus': 50, 'Sutter': 51, 'Tehama': 52, 'Trinity': 53, 'Tulare': 54, 'Tuolumne': 55, 'Ventura': 56, 'Yolo': 57, 'Yuba': 58}\n",
    "\n",
    "all_popu_data = []\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "for year in sheet_names:\n",
    "    single_county_df = pd.read_excel(file_path, sheet_name=year)\n",
    "    single_county_df.replace(county_map, inplace=True)\n",
    "    \n",
    "    date_range = pd.date_range(start=f'{year}-01-01', end=f'{year}-12-31')\n",
    "    \n",
    "    for county_id in single_county_df.County:\n",
    "        row = pd.concat([single_county_df.loc[single_county_df['County'] == county_id]] * len(date_range), ignore_index=True)\n",
    "        row['Date'] = date_range\n",
    "        all_popu_data.append(row.copy())\n",
    "\n",
    "all_popu_data = pd.concat(all_popu_data, axis=0, ignore_index=True)\n",
    "all_popu_data.rename(columns={'County': 'County_id'}, inplace=True)\n",
    "all_popu_data.loc[:, 'Date'] = pd.to_datetime(all_popu_data['Date'], format='mixed')\n",
    "all_popu_data['Date'] = all_popu_data['Date'].astype(str)\n",
    "all_popu_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add DVMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211874, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'./data/DVMT 2012-2021.xlsx'\n",
    "sheets = pd.ExcelFile(file_path)\n",
    "sheet_names = sorted(sheets.sheet_names)\n",
    "\n",
    "all_dvmt_data = []\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "for year in sheet_names:\n",
    "    single_county_df = pd.read_excel(file_path, sheet_name=year)\n",
    "    \n",
    "    date_range = pd.date_range(start=f'{year}-01-01', end=f'{year}-12-31')\n",
    "    \n",
    "    for county_id in single_county_df.County_ID:\n",
    "        row = pd.concat([single_county_df.loc[single_county_df['County_ID'] == county_id]] * len(date_range), ignore_index=True)\n",
    "        row['Date'] = date_range\n",
    "        all_dvmt_data.append(row.copy())\n",
    "\n",
    "all_dvmt_data = pd.concat(all_dvmt_data, axis=0, ignore_index=True)\n",
    "all_dvmt_data.rename(columns={'County_ID': 'County_id'}, inplace=True)\n",
    "all_dvmt_data.drop(columns=['City_County'], axis=1, inplace=True)\n",
    "all_dvmt_data.loc[:, 'Date'] = pd.to_datetime(all_dvmt_data['Date'], format='mixed')\n",
    "all_dvmt_data['Date'] = all_dvmt_data['Date'].astype(str)\n",
    "\n",
    "all_dvmt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = ['crash']\n",
    "\n",
    "if add_adj:\n",
    "    save_path.append('adj')\n",
    "\n",
    "if add_vict:\n",
    "    all_adj_data = pd.merge(crash_data, all_adj_data, on=['County_id', 'Date'], how='outer')\n",
    "    save_path.append('vict')\n",
    "else:\n",
    "    all_adj_data = crash_data.copy()\n",
    "\n",
    "if add_popu:\n",
    "    all_adj_data = pd.merge(all_popu_data, all_adj_data, on=['County_id', 'Date'], how='outer')\n",
    "    save_path.append('popu')\n",
    "\n",
    "if add_dvmt:\n",
    "    all_adj_data = pd.merge(all_dvmt_data, all_adj_data, on=['County_id', 'Date'], how='outer')\n",
    "    save_path.append('dvmt')\n",
    "\n",
    "all_adj_data.dropna(axis=0, inplace=True)\n",
    "save_path = './' + '_'.join(save_path) + '.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adj_data.to_csv('./adj_vict_popu_dvmt_crash.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "County_id                   0\n",
       "Date                        0\n",
       "Fatal                       0\n",
       "Injury Severe               0\n",
       "Injury Other Visible        0\n",
       "                           ..\n",
       "Adjacency_58                0\n",
       "Killed                      0\n",
       "Suspected Serious Injury    0\n",
       "Suspected Minor Injury      0\n",
       "Possible Injury             0\n",
       "Length: 68, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_adj_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [County_id, Date, Fatal, Injury Severe, Injury Other Visible, Injury Complaint of Pain, Adjacency_1, Adjacency_2, Adjacency_3, Adjacency_4, Adjacency_5, Adjacency_6, Adjacency_7, Adjacency_8, Adjacency_9, Adjacency_10, Adjacency_11, Adjacency_12, Adjacency_13, Adjacency_14, Adjacency_15, Adjacency_16, Adjacency_17, Adjacency_18, Adjacency_19, Adjacency_20, Adjacency_21, Adjacency_22, Adjacency_23, Adjacency_24, Adjacency_25, Adjacency_26, Adjacency_27, Adjacency_28, Adjacency_29, Adjacency_30, Adjacency_31, Adjacency_32, Adjacency_33, Adjacency_34, Adjacency_35, Adjacency_36, Adjacency_37, Adjacency_38, Adjacency_39, Adjacency_40, Adjacency_41, Adjacency_42, Adjacency_43, Adjacency_44, Adjacency_45, Adjacency_46, Adjacency_47, Adjacency_48, Adjacency_49, Adjacency_50, Adjacency_51, Adjacency_52, Adjacency_53, Adjacency_54, Adjacency_55, Adjacency_56, Adjacency_57, Adjacency_58, Killed, Suspected Serious Injury, Suspected Minor Injury, Possible Injury]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_adj_data[all_adj_data.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Applying shift window \n",
    "- **Function `shift_window(df, W)`**:\n",
    "  - Sorts DataFrame by `'Date'` and resets index.\n",
    "  - Prepares target DataFrame `targets_df` from window size `W` onward.\n",
    "  - Drops `'Date'` column and converts DataFrame to numpy array.\n",
    "  - Initializes array for windowed data.\n",
    "  - Fills array with sliding window data.\n",
    "  - Reshapes and converts windowed data back to DataFrame `features_df`, re-adding expanded dates.\n",
    "  - Returns `features_df` and `targets_df`.\n",
    "\n",
    "- **Main Loop**:\n",
    "  - Iterates through unique `County_id` values in `all_adj_data`.\n",
    "  - Applies `shift_window` to each county's data with window size `W = 7`.\n",
    "  - Appends results to `all_features_df` and `all_targets_df`.\n",
    "\n",
    "This process prepares windowed features and targets for each county, facilitating time series analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_window(df, W):\n",
    "    # cols = ['Date', 'Killed', 'Suspected Serious Injury',\n",
    "    #         'Suspected Minor Injury', 'Possible Injury']\n",
    "    cols = ['Date', 'Fatal', 'Injury Severe', \n",
    "            'Injury Other Visible', 'Injury Complaint of Pain']\n",
    "    df_sorted = df.sort_values(by='Date')\n",
    "    df = df_sorted.reset_index(drop=True)\n",
    "    date = df[['Date']]\n",
    "    \n",
    "    data = df.values\n",
    "    M, N = df.shape\n",
    "    targets = data[W:M, :]\n",
    "    targets_df = pd.DataFrame(targets, index=range(W, M), columns=df.columns)\n",
    "    targets_df = targets_df[cols]\n",
    "    targets_df['Date'] = pd.to_datetime(targets_df['Date'], format='mixed')\n",
    "    # Step 1: Convert DataFrame to numpy array\n",
    "\n",
    "    df = df.drop(columns=['Date'], axis=1)\n",
    "    data = df.values\n",
    "    M, N = df.shape\n",
    "\n",
    "    # Step 2: Create a new array to store the windows\n",
    "    result = np.empty((M - W, W, N))\n",
    "\n",
    "    # Step 3: Fill the result array with windowed data\n",
    "    for i in range(M - W):\n",
    "        result[i] = data[i:i+W]\n",
    "\n",
    "    # Convert features to DataFrame\n",
    "    features_flat = result.reshape(-1, N)\n",
    "    index_features = pd.MultiIndex.from_product([range(M - W), range(W)], names=['row', 'window'])\n",
    "    features_df = pd.DataFrame(features_flat, index=index_features, columns=df.columns)\n",
    "\n",
    "    dates_expanded = np.array([date[i:i+W] for i in range(M - W)]).reshape(-1)\n",
    "    features_df['Date'] = pd.to_datetime(dates_expanded, format='mixed')\n",
    "\n",
    "    return features_df, targets_df\n",
    "\n",
    "window_size = 7\n",
    "all_features_df = []\n",
    "all_targets_df = []\n",
    "for county_id in range(1, len(all_adj_data['County_id'].unique()) + 1):\n",
    "    features_df, targets_df = shift_window(all_adj_data.loc[all_adj_data['County_id'] == county_id], window_size)\n",
    "    all_features_df.append(features_df.copy())\n",
    "    all_targets_df.append(targets_df.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- filtering the subset contain the last month of the last year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "X_train_df, y_train_df, X_test_df, y_test_df = [], [], [], []\n",
    "for county_id in range(1, len(all_adj_data['County_id'].unique()) + 1):\n",
    "    single_x = all_features_df[county_id-1]\n",
    "    single_y = all_targets_df[county_id-1]\n",
    "    # print(len(single_x), len(single_y))\n",
    "\n",
    "    latest_date = single_x['Date'].max()\n",
    "\n",
    "    # Calculate the start date for the one-month range\n",
    "    one_month_ago = latest_date - timedelta(days=30)\n",
    "\n",
    "    # Filter the DataFrame to get the last one month of data\n",
    "    i, j = single_x[single_x['Date'] == one_month_ago].index[0]\n",
    "    single_x['year'] = single_x['Date'].dt.year\n",
    "    single_x['month'] = single_x['Date'].dt.month\n",
    "    single_x['day_of_week'] = single_x['Date'].dt.dayofweek\n",
    "    single_x.drop(columns=['Date'], axis=1, inplace=True)\n",
    "    test_data = single_x.loc[(i+1, 0): ]\n",
    "    train_data = single_x.loc[:(i, j)]\n",
    "    \n",
    "    last_row = single_y[single_y['Date'] > one_month_ago].index[0]\n",
    "    single_y.drop(columns=['Date'], axis=1, inplace=True)\n",
    "    test_label = single_y.loc[last_row+1:]\n",
    "    train_label = single_y.loc[:last_row]\n",
    "    train_label = train_label.apply(pd.to_numeric)\n",
    "    test_label = test_label.apply(pd.to_numeric)\n",
    "    \n",
    "    X_train_df.append(train_data.copy())\n",
    "    X_test_df.append(test_data.copy())\n",
    "    y_train_df.append(train_label.copy())\n",
    "    y_test_df.append(test_label.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Function Definition**:\n",
    "  - `pandas_to_numpy(df)`: Converts a multi-index DataFrame to a 3D numpy array.\n",
    "\n",
    "- **Combining Data**:\n",
    "  - Vertically stacks the arrays in `X_train`, `y_train`, `X_test`, and `y_test` to form final 3D arrays.\n",
    "\n",
    "This process prepares and consolidates training and testing datasets into 3D numpy arrays for machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_numpy(df):\n",
    "    M = len(df.index.get_level_values('row').unique())\n",
    "    W = len(df.index.get_level_values('window').unique())\n",
    "    N = df.shape[1]\n",
    "    array_3d = df.values.reshape(M, W, N)\n",
    "    return array_3d\n",
    "\n",
    "X_train, y_train, X_test, y_test = [], [], [], []\n",
    "for i in range(len(X_train_df)):\n",
    "    x_obj = pandas_to_numpy(X_train_df[i])\n",
    "    y_obj = y_train_df[i].values\n",
    "    X_train.append(x_obj)\n",
    "    y_train.append(y_obj)\n",
    "\n",
    "for i in range(len(X_test_df)):\n",
    "    x_obj = pandas_to_numpy(X_test_df[i])\n",
    "    y_obj = y_test_df[i].values\n",
    "    X_test.append(x_obj)\n",
    "    y_test.append(y_obj)\n",
    "\n",
    "X_train = np.vstack(X_train)\n",
    "y_train = np.vstack(y_train)\n",
    "X_test = np.vstack(X_test)\n",
    "y_test = np.vstack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./crash_adj_vict.npy\n"
     ]
    }
   ],
   "source": [
    "print(save_path)\n",
    "with open(save_path, 'wb') as f:\n",
    "    np.save(f, np.array([X_train, y_train, X_test, y_test], dtype='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252066, 7, 70)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the X_train dataset is a 3-dimensional numpy array with the following dimensions:\n",
    "\n",
    "- 252068: This is the number of samples in training dataset.\n",
    "- 7: This represents the window size, meaning each sample consists of 7 time steps (or windows).\n",
    "- 66: This is the number of features for each time step in the window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
